{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/stefanoridolfi/Coding_ML/blob/master/MLP_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "73AuA8XzdsGZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "@np.vectorize\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.e ** -x)\n",
        "activation_function = sigmoid\n",
        "from scipy.stats import truncnorm\n",
        "def truncated_normal(mean=0, sd=1, low=0, upp=10):\n",
        "    return truncnorm(\n",
        "        (low - mean) / sd, (upp - mean) / sd, loc=mean, scale=sd)\n",
        "class NeuralNetwork:\n",
        "    \n",
        "    def __init__(self, \n",
        "                 no_of_in_nodes, \n",
        "                 no_of_out_nodes, \n",
        "                 no_of_hidden_nodes,\n",
        "                 learning_rate):\n",
        "        self.no_of_in_nodes = no_of_in_nodes\n",
        "        self.no_of_out_nodes = no_of_out_nodes\n",
        "        self.no_of_hidden_nodes = no_of_hidden_nodes\n",
        "        self.learning_rate = learning_rate \n",
        "        self.create_weight_matrices()\n",
        "        \n",
        "    def create_weight_matrices(self):\n",
        "        \"\"\" A method to initialize the weight matrices of the neural network\"\"\"\n",
        "        rad = 1 / np.sqrt(self.no_of_in_nodes)\n",
        "        X = truncated_normal(mean=0, sd=1, low=-rad, upp=rad)\n",
        "        self.weights_in_hidden = X.rvs((self.no_of_hidden_nodes, \n",
        "                                       self.no_of_in_nodes))\n",
        "        \n",
        "        # print matrice pesi input - hidden\n",
        "        #print(\"matrice pesi input - hidden\", self.weights_in_hidden)\n",
        "        X = truncated_normal(mean=0, sd=1, low=-rad, upp=rad)\n",
        "        self.weights_hidden_out = X.rvs((self.no_of_out_nodes, \n",
        "                                        self.no_of_hidden_nodes))\n",
        "        #print(\"tipo di self.weights_in_hidden=\", type(self.weights_in_hidden))\n",
        "        # print matrice pesi hidden-output\n",
        "        #print(\"matrice pesi hidden-output\",self.weights_hidden_out )\n",
        "    def train(self, input_vector, target_vector):\n",
        "        # input_vector and target_vector can be tuple, list or ndarray\n",
        "        #print(\" input_vector originale e tipo\",  input_vector, type( input_vector))\n",
        "        input_vector = np.array(input_vector, ndmin=2).T\n",
        "        #print(\" input_vector dopo arrya e tipo\",  input_vector, type( input_vector))\n",
        "        target_vector = np.array(target_vector, ndmin=2).T\n",
        "        #print(\"input vector\", input_vector.T,\"target vector\",target_vector.T )\n",
        "        #print(\"1111111111111111111111111111111111111111111111111111111111\")\n",
        "        \n",
        "\n",
        "        output_vector1 = np.dot(self.weights_in_hidden, input_vector)\n",
        "        #print(\"tipo di output_vector1=\", type(output_vector1))\n",
        "        output_vector_hidden = activation_function(output_vector1)\n",
        "        #print(\"output_vector1=\", output_vector1.T,\"output_vector_hidden= \", output_vector_hidden.T, \" Calcolo diretta funz. attivazione sigmoide \",(1 / (1 + np.e ** -output_vector1)) )\n",
        "        output_vector2 = np.dot(self.weights_hidden_out, output_vector_hidden)\n",
        "        output_vector_network = activation_function(output_vector2)\n",
        "        \n",
        "        output_errors = target_vector - output_vector_network\n",
        "        # update the weights:\n",
        "        \n",
        "        tmp = output_errors * output_vector_network * (1.0 - output_vector_network)     \n",
        "        \n",
        "        #print(\"tmp = output_errors * output_vector_network * (1.0 - output_vector_network)  =\",tmp, \"output_errors=\",output_errors, \"output_vector_network=\",output_vector_network, \"1.0 - output_vector_network=\", (1.0 - output_vector_network),\"FFFF\")\n",
        "        \n",
        "        tmp = self.learning_rate  * np.dot(tmp, output_vector_hidden.T)\n",
        "        self.weights_hidden_out += tmp\n",
        "        # calculate hidden errors:\n",
        "        hidden_errors = np.dot(self.weights_hidden_out.T, output_errors)\n",
        "        # update the weights:\n",
        "        tmp = hidden_errors * output_vector_hidden * (1.0 - output_vector_hidden)\n",
        "        self.weights_in_hidden += self.learning_rate * np.dot(tmp, input_vector.T)\n",
        "           \n",
        "    \n",
        "    def run(self, input_vector):\n",
        "        # input_vector can be tuple, list or ndarray\n",
        "        input_vector = np.array(input_vector, ndmin=2).T\n",
        "        output_vector = np.dot(self.weights_in_hidden, input_vector)\n",
        "        output_vector = activation_function(output_vector)\n",
        "        \n",
        "        output_vector = np.dot(self.weights_hidden_out, output_vector)\n",
        "        output_vector = activation_function(output_vector)\n",
        "        print(\"output_vector:::\",output_vector)\n",
        "    \n",
        "        return output_vector\n",
        "            "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kl4lfcpSdyEZ",
        "colab_type": "code",
        "outputId": "ea16bc93-59e4-46bf-800a-62c7daf71ebd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "data1 = [((3, 4), (0.99, 0.01)), ((4.2, 5.3), (0.99, 0.01)), \n",
        "         ((4, 3), (0.99, 0.01)), ((6, 5), (0.99, 0.01)), \n",
        "         ((4, 6), (0.99, 0.01)), ((3.7, 5.8), (0.99, 0.01)), \n",
        "         ((3.2, 4.6), (0.99, 0.01)), ((5.2, 5.9), (0.99, 0.01)), \n",
        "         ((5, 4), (0.99, 0.01)), ((7, 4), (0.99, 0.01)), \n",
        "         ((3, 7), (0.99, 0.01)), ((4.3, 4.3), (0.99, 0.01))]\n",
        "data2 = [((-3, -4), (0.01, 0.99)), ((-2, -3.5), (0.01, 0.99)), \n",
        "         ((-1, -6), (0.01, 0.99)), ((-3, -4.3), (0.01, 0.99)), \n",
        "         ((-4, -5.6), (0.01, 0.99)), ((-3.2, -4.8), (0.01, 0.99)), \n",
        "         ((-2.3, -4.3), (0.01, 0.99)), ((-2.7, -2.6), (0.01, 0.99)), \n",
        "         ((-1.5, -3.6), (0.01, 0.99)), ((-3.6, -5.6), (0.01, 0.99)), \n",
        "         ((-4.5, -4.6), (0.01, 0.99)), ((-3.7, -5.8), (0.01, 0.99))]\n",
        "data = data1 + data2\n",
        "np.random.shuffle(data)\n",
        "points1, labels1 = zip(*data1)\n",
        "X, Y = zip(*points1)\n",
        "plt.scatter(X, Y, c=\"r\")\n",
        "points2, labels2 = zip(*data2)\n",
        "X, Y = zip(*points2)\n",
        "plt.scatter(X, Y, c=\"b\")\n",
        "plt.show()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXIAAAD4CAYAAADxeG0DAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nkiPIASA5ghwAkiPIASC5/wfD396f/kATwQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "eed1e34a-09ce-4efb-9fd1-f928a1f81bd6",
        "id": "0QvO9zDgeJxG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 583
        }
      },
      "source": [
        "simple_network = NeuralNetwork(no_of_in_nodes=2, \n",
        "                               no_of_out_nodes=2, \n",
        "                               no_of_hidden_nodes=2,\n",
        "                               learning_rate=0.6)\n",
        "    \n",
        "size_of_learn_sample = int(len(data)*0.9)\n",
        "learn_data = data[:size_of_learn_sample]\n",
        "test_data = data[-size_of_learn_sample:]\n",
        "size_of_test_sample = len(data)-size_of_learn_sample \n",
        "#print(\"__________________________________________________________________\")\n",
        "for i in range(size_of_learn_sample):\n",
        "    point, label = learn_data[i][0], learn_data[i][1]\n",
        "    print(\"point=\", point,\"label=\",label)\n",
        "    simple_network.train(point, label)\n",
        "    \n",
        "for i in range(size_of_test_sample):\n",
        "    point, label = test_data[i][0], test_data[i][1]\n",
        "    cls1, cls2 =simple_network.run(point)\n",
        "    print(point, cls1, cls2, end=\": \")\n",
        "    if cls1 > cls2:\n",
        "        if label == (0.99, 0.01):\n",
        "            print(\"class1 correct\", label)\n",
        "        else:\n",
        "            print(\"class2 incorrect\", label)\n",
        "    else:\n",
        "        if label == (0.01, 0.99):\n",
        "            print(\"class1 correct\", label)\n",
        "        else:\n",
        "            print(\"class2 incorrect\", label)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "point= (4.3, 4.3) label= (0.99, 0.01)\n",
            "point= (-3, -4.3) label= (0.01, 0.99)\n",
            "point= (-2.7, -2.6) label= (0.01, 0.99)\n",
            "point= (-3, -4) label= (0.01, 0.99)\n",
            "point= (-3.6, -5.6) label= (0.01, 0.99)\n",
            "point= (4.2, 5.3) label= (0.99, 0.01)\n",
            "point= (-4.5, -4.6) label= (0.01, 0.99)\n",
            "point= (3, 7) label= (0.99, 0.01)\n",
            "point= (-2, -3.5) label= (0.01, 0.99)\n",
            "point= (5, 4) label= (0.99, 0.01)\n",
            "point= (3.7, 5.8) label= (0.99, 0.01)\n",
            "point= (5.2, 5.9) label= (0.99, 0.01)\n",
            "point= (-1, -6) label= (0.01, 0.99)\n",
            "point= (-3.2, -4.8) label= (0.01, 0.99)\n",
            "point= (-2.3, -4.3) label= (0.01, 0.99)\n",
            "point= (6, 5) label= (0.99, 0.01)\n",
            "point= (4, 3) label= (0.99, 0.01)\n",
            "point= (3.2, 4.6) label= (0.99, 0.01)\n",
            "point= (7, 4) label= (0.99, 0.01)\n",
            "point= (3, 4) label= (0.99, 0.01)\n",
            "point= (-3.7, -5.8) label= (0.01, 0.99)\n",
            "output_vector::: [[0.47039136]\n",
            " [0.74577056]]\n",
            "(-3, -4) [0.47039136] [0.74577056]: class1 correct (0.01, 0.99)\n",
            "output_vector::: [[0.46838841]\n",
            " [0.75083009]]\n",
            "(-3.6, -5.6) [0.46838841] [0.75083009]: class1 correct (0.01, 0.99)\n",
            "output_vector::: [[0.58067583]\n",
            " [0.32544726]]\n",
            "(4.2, 5.3) [0.58067583] [0.32544726]: class1 correct (0.99, 0.01)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}